{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-28 09:48:16.325069: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-28 09:48:16.927926: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using concept features\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import torch \n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils import pad_collate\n",
    "from dataloader_comma import CommaDataset\n",
    "from dataloader_nuscenes import NUScenesDataset\n",
    "from collections import Counter\n",
    "import imageio\n",
    "from model import VTN\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "from scipy.stats import pearsonr\n",
    "plt.rcParams.update({'font.size': 16}) \n",
    "import os\n",
    "from utils import * \n",
    "import re\n",
    "from vis_utils import * \n",
    "from tqdm import tqdm\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(checkpoint_path, map_location=gpu)\n",
    "state_dict = ckpt['state_dict']\n",
    "state_dict = get_regular_ckpt_from_lightning_checkpoint(state_dict)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "model = model.to(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_string(string):\n",
    "    words = string.split()#.replace(\"a photo of driving on a highway with\", \"\").replace(\"a photo of\", \"\").replace(\"driving on a highway\", \"\").replace(\"past\", \"\").replace(\"a street with\", \"\").split()  # Split the string into a list of words\n",
    "    result = []\n",
    "    current_line = \"\"\n",
    "    \n",
    "    for word in words:\n",
    "        if len(current_line) + len(word) <= 40:\n",
    "            current_line += word + \" \"\n",
    "        else:\n",
    "            result.append(current_line.strip())\n",
    "            current_line = word + \" \"\n",
    "    \n",
    "    if current_line:\n",
    "        result.append(current_line.strip())\n",
    "    \n",
    "    return \"\\n\".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "215it [00:44,  4.79it/s]\n",
      "[rawvideo @ 0x60fa680] Stream #0: not enough frames to estimate rate; consider increasing probesize\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All images in a movie should have same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 127\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39m# Save the frames as a GIF\u001b[39;00m\n\u001b[1;32m    125\u001b[0m frames[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/home/jessica/personalized_driving_toyota/result_images/mturk/att/w_attention_nusc_\u001b[39m\u001b[39m{\u001b[39;00mj\u001b[39m}\u001b[39;00m\u001b[39m.gif\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mGIF\u001b[39m\u001b[39m'\u001b[39m, append_images\u001b[39m=\u001b[39mframes[\u001b[39m1\u001b[39m:], save_all\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    126\u001b[0m            duration\u001b[39m=\u001b[39mframe_duration, loop\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m--> 127\u001b[0m imageio\u001b[39m.\u001b[39;49mmimsave(output_path(\u001b[39m\"\u001b[39;49m\u001b[39m2\u001b[39;49m\u001b[39m\"\u001b[39;49m), frames, fps\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    128\u001b[0m \u001b[39m#imageio.mimsave(output_path(\"1\"), frames[40:56], fps=2)\u001b[39;00m\n\u001b[1;32m    130\u001b[0m directory \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/home/jessica/personalized_driving_toyota/result_images/mturk\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/imageio/v2.py:495\u001b[0m, in \u001b[0;36mmimwrite\u001b[0;34m(uri, ims, format, **kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m imopen_args[\u001b[39m\"\u001b[39m\u001b[39mlegacy_mode\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[39mwith\u001b[39;00m imopen(uri, \u001b[39m\"\u001b[39m\u001b[39mwI\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mimopen_args) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m--> 495\u001b[0m     \u001b[39mreturn\u001b[39;00m file\u001b[39m.\u001b[39;49mwrite(ims, is_batch\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/imageio/core/legacy_plugin_wrapper.py:253\u001b[0m, in \u001b[0;36mLegacyPlugin.write\u001b[0;34m(self, ndimage, is_batch, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(image\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39mnumber) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(\n\u001b[1;32m    247\u001b[0m             image\u001b[39m.\u001b[39mdtype, \u001b[39mbool\u001b[39m\n\u001b[1;32m    248\u001b[0m         ):\n\u001b[1;32m    249\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    250\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAll images have to be numeric, and not `\u001b[39m\u001b[39m{\u001b[39;00mimage\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    251\u001b[0m             )\n\u001b[0;32m--> 253\u001b[0m         writer\u001b[39m.\u001b[39;49mappend_data(image, metadata)\n\u001b[1;32m    255\u001b[0m \u001b[39mreturn\u001b[39;00m writer\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/imageio/core/format.py:590\u001b[0m, in \u001b[0;36mFormat.Writer.append_data\u001b[0;34m(self, im, meta)\u001b[0m\n\u001b[1;32m    588\u001b[0m im \u001b[39m=\u001b[39m asarray(im)\n\u001b[1;32m    589\u001b[0m \u001b[39m# Call\u001b[39;00m\n\u001b[0;32m--> 590\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_append_data(im, total_meta)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/imageio/plugins/ffmpeg.py:591\u001b[0m, in \u001b[0;36mFfmpegFormat.Writer._append_data\u001b[0;34m(self, im, meta)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[39m# Check size of image\u001b[39;00m\n\u001b[1;32m    590\u001b[0m \u001b[39mif\u001b[39;00m size \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_size:\n\u001b[0;32m--> 591\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAll images in a movie should have same size\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    592\u001b[0m \u001b[39mif\u001b[39;00m depth \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_depth:\n\u001b[1;32m    593\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    594\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAll images in a movie should have same \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnumber of channels\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    595\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All images in a movie should have same size"
     ]
    }
   ],
   "source": [
    "#for j, batch in enumerate(dataloader_nuscenes):\n",
    "#    _, image_array,  vego, angle, distance, _, _, _, _, _ = batch\n",
    "for j, batch in enumerate(dataloader_comma):\n",
    "    if j != 3: continue\n",
    "    image_array,  vego, angle, distance, g, s, l = batch\n",
    "    img = image_array\n",
    "    max_len = 240\n",
    "    img, angle, distance, vego = img.to(gpu), angle.to(gpu), distance.to(gpu), vego.to(gpu)\n",
    "    (logits, attns), concepts = model(img, angle, distance, vego)\n",
    "    top5_indices_res = torch.tensor(concepts.squeeze()).topk(10)\n",
    "    top5_indices = top5_indices_res.indices\n",
    "    s = img.shape\n",
    "    angle, distance, vego, logits, concepts = angle.to(\"cpu\"), distance.to(\"cpu\"), vego.to(\"cpu\"), logits.detach().cpu().to(\"cpu\"), concepts.detach().cpu().to(\"cpu\")\n",
    "\n",
    "    atten = attns[2][:,:,0:concepts.shape[1]].detach()\n",
    "    seq_len = atten.shape[2]\n",
    "    alignment_array = get_aligned_attention(atten.squeeze().cpu(), seq_len)\n",
    "    speed_graph_2 = alignment_array.sum(axis=0)[8:-8]\n",
    "    speed_graph_2 = moving_average(speed_graph_2, 10)[10:-15]\n",
    "\n",
    "    atten = attns[0][:,:,0:concepts.shape[1]].detach()\n",
    "    seq_len = atten.shape[2]\n",
    "    alignment_array = get_aligned_attention(atten.squeeze().cpu(), seq_len)\n",
    "    speed_graph_0 = alignment_array.sum(axis=0)[8:-8]\n",
    "    speed_graph_0 = moving_average(speed_graph_0, 10)[10:-15]\n",
    "\n",
    "    atten = attns[1][:,:,0:concepts.shape[1]].detach()\n",
    "    seq_len = atten.shape[2]\n",
    "    alignment_array = get_aligned_attention(atten.squeeze().cpu(), seq_len)\n",
    "    speed_graph_1 = alignment_array.sum(axis=0)[8:-8]\n",
    "    speed_graph_1 = moving_average(speed_graph_1, 10)[10:-15]\n",
    "\n",
    "    \n",
    "    f = []\n",
    "    inter = []\n",
    "    \n",
    "    for i, elem0 in enumerate(top5_indices):\n",
    "        #print(top5_indices_res.values[i])\n",
    "        #print(elem0)\n",
    "        inter = []\n",
    "        for elem in top5_indices[max(i-10, 0):min(i+10,len(top5_indices))]:\n",
    "            l = elem.cpu().numpy().tolist()\n",
    "            if 131 in l:\n",
    "                l.remove(131)\n",
    "            if 55 in l:\n",
    "                l.remove(55)\n",
    "            if 14 in l:\n",
    "                l.remove(14)\n",
    "            if 17 in l:\n",
    "                l.remove(17)\n",
    "            inter.extend(l)\n",
    "        count_dict = Counter(inter)\n",
    "        # Get the top 5 most occurring numbers\n",
    "        top_5 = count_dict.most_common(3)\n",
    "        intermediate = []\n",
    "        for a in top_5: \n",
    "            intermediate.append(scenarios[a[0]])\n",
    "        #print(intermediate)\n",
    "        f.append(intermediate)\n",
    "    \n",
    "    #fig, axes = plt.subplots(1, 1, figsize=(12, 16))#,gridspec_kw= {'height_ratios': [20, 1]})\n",
    "    \n",
    "    plt_idx = 0\n",
    "    for i, image in tqdm(enumerate(img[0][10:-15])):\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(8, 12),gridspec_kw= {'height_ratios': [2, 1], 'hspace': 0, 'wspace': 0})\n",
    "        plt.subplots_adjust(hspace=0, wspace=0)\n",
    "    \n",
    "        image_frame = (image).cpu().permute(1, 2, 0)\n",
    "\n",
    "        axes[0].imshow((np.array(image_frame) * 255).astype(np.uint8))\n",
    "        \n",
    "        title = '\\n'.join([split_string(\"\\u2022 \" + h) for h in f[i]])\n",
    "        axes[0].set_title(title)\n",
    "        axes[0].set_aspect('equal')\n",
    "        axes[0].set_xticks([])\n",
    "        axes[0].set_yticks([])\n",
    "\n",
    "        # Remove borders\n",
    "        axes[0].spines['top'].set_visible(False)\n",
    "        axes[0].spines['bottom'].set_visible(False)\n",
    "        axes[0].spines['left'].set_visible(False)\n",
    "        axes[0].spines['right'].set_visible(False)\n",
    "\n",
    "        # Plot the speed graph\n",
    "        #axes[1].plot(speed_graph_2, label='Attention', color='black')\n",
    "        #axes[1].plot(speed_graph_1, label='Attention', color='red')\n",
    "        axes[1].plot(speed_graph_0, label='Attention', color='green')\n",
    "    \n",
    "\n",
    "        axes[1].set_xlabel('Time Step')\n",
    "\n",
    "        #axes[1].plot(i, speed_graph_2[i], marker='o', markersize=10, color='black')\n",
    "        axes[1].plot(i, speed_graph_0[i], marker='o', markersize=10, color='green')\n",
    "        #axes[1].plot(i, speed_graph_1[i], marker='o', markersize=10, color='red')\n",
    "        axes[1].spines['top'].set_visible(False)\n",
    "        axes[1].spines['right'].set_visible(False)\n",
    "    \n",
    "        plt.savefig(f\"/home/jessica/personalized_driving_toyota/result_images/mturk/{i}.png\")\n",
    "        plt.close()\n",
    "\n",
    "    \n",
    "    image_directory = '/home/jessica/personalized_driving_toyota/result_images/mturk/'\n",
    "\n",
    "    # Set the output GIF file path\n",
    "    output_path = lambda x: f'/home/jessica/personalized_driving_toyota/result_images/mturk/att/w_attention_nusc_{j}_{x}.mp4'\n",
    "\n",
    "    # Set the duration (in milliseconds) for each frame in the GIF\n",
    "    frame_duration = 8000\n",
    "\n",
    "    # Get a sorted list of image files in the directory\n",
    "    image_files = sorted(glob.glob(f'{image_directory}/*.png'), key=extract_number)  # Adjust the file extension if necessary\n",
    "\n",
    "    # Create a list to store the frames of the GIF\n",
    "    frames = []\n",
    "\n",
    "    # Iterate over each image file\n",
    "    for image_file in image_files:\n",
    "        # Open the image file\n",
    "        image = Image.open(image_file)\n",
    "\n",
    "        # Add the image to the list of frames\n",
    "        frames.append(image)\n",
    "\n",
    "    # Save the frames as a GIF\n",
    "    frames[0].save(f'/home/jessica/personalized_driving_toyota/result_images/mturk/att/w_attention_nusc_{j}.gif', format='GIF', append_images=frames[1:], save_all=True,\n",
    "               duration=frame_duration, loop=0)\n",
    "    imageio.mimsave(output_path(\"2\"), frames, fps=1)\n",
    "    #imageio.mimsave(output_path(\"1\"), frames[40:56], fps=2)\n",
    "\n",
    "    directory = '/home/jessica/personalized_driving_toyota/result_images/mturk'\n",
    "    '''for filename in os.listdir(directory):\n",
    "        if filename.endswith('.png'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            os.remove(file_path)'''\n",
    "    if j > 50: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220 torch.Size([1, 220])\n",
      "220 torch.Size([1, 220])\n",
      "220 torch.Size([1, 220])\n",
      "220 torch.Size([1, 220])\n",
      "220 torch.Size([1, 220])\n",
      "220 torch.Size([1, 220])\n",
      "220 torch.Size([1, 220])\n",
      "220 torch.Size([1, 220])\n",
      "220 torch.Size([1, 220])\n",
      "220 torch.Size([1, 220])\n",
      "220 torch.Size([1, 220])\n",
      "220 torch.Size([1, 220])\n",
      "220 torch.Size([1, 220])\n",
      "220 torch.Size([1, 220])\n",
      "220 torch.Size([1, 220])\n",
      "220 torch.Size([1, 220])\n",
      "220 torch.Size([1, 220])\n",
      "220 torch.Size([1, 220])\n",
      "220 torch.Size([1, 220])\n",
      "220 torch.Size([1, 220])\n",
      "220 torch.Size([1, 220])\n",
      "220 torch.Size([1, 220])\n",
      "220 torch.Size([1, 220])\n",
      "220 torch.Size([1, 220])\n",
      "220 torch.Size([1, 220])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sg1 = []\n",
    "sg2 = []\n",
    "sg3 = []\n",
    "angles = []\n",
    "dists = []\n",
    "vegs = []\n",
    "for j, batch in enumerate(dataloader_comma):\n",
    "    image_array,  vego, angle, distance, g, s, l = batch\n",
    "    img = image_array\n",
    "    max_len = 240\n",
    "    img, angle, distance, vego = img.to(gpu), angle.to(gpu), distance.to(gpu), vego.to(gpu)\n",
    "    (logits, attns), concepts = model(img, angle, distance, vego)\n",
    "    top5_indices_res = torch.tensor(concepts.squeeze()).topk(10)\n",
    "    top5_indices = top5_indices_res.indices\n",
    "    s = img.shape\n",
    "    angle, distance, vego, logits, concepts = angle.to(\"cpu\")[:, 10:-10], distance.to(\"cpu\")[:, 10:-10], vego.to(\"cpu\")[:, 10:-10], logits.detach().cpu().to(\"cpu\"), concepts.detach().cpu().to(\"cpu\")\n",
    "\n",
    "    atten = attns[2][:,:,0:concepts.shape[1]].detach()\n",
    "    seq_len = atten.shape[2]\n",
    "    alignment_array = get_aligned_attention(atten.squeeze().cpu(), seq_len)\n",
    "    speed_graph_2 = alignment_array.sum(axis=0)[8:-8]\n",
    "    \n",
    "    speed_graph_2 = moving_average(speed_graph_2, 10)[10:-10]\n",
    "\n",
    "    atten = attns[0][:,:,0:concepts.shape[1]].detach()\n",
    "    seq_len = atten.shape[2]\n",
    "    alignment_array = get_aligned_attention(atten.squeeze().cpu(), seq_len)\n",
    "    speed_graph_0 = alignment_array.sum(axis=0)[8:-8]\n",
    "    speed_graph_0 = moving_average(speed_graph_0, 10)[10:-10]\n",
    "\n",
    "    atten = attns[1][:,:,0:concepts.shape[1]].detach()\n",
    "    seq_len = atten.shape[2]\n",
    "    alignment_array = get_aligned_attention(atten.squeeze().cpu(), seq_len)\n",
    "    speed_graph_1 = alignment_array.sum(axis=0)[8:-8]\n",
    "    speed_graph_1 = moving_average(speed_graph_1, 10)[10:-10]\n",
    "    print(len(speed_graph_1), angle.shape)\n",
    "    sg1.extend(speed_graph_0)\n",
    "    sg2.extend(speed_graph_1)\n",
    "    sg3.extend(speed_graph_2)\n",
    "    dists.extend(distance.squeeze().tolist())\n",
    "    vegs.extend(vego.squeeze().tolist())\n",
    "    angles.extend(angle.squeeze().tolist())\n",
    "\n",
    "\n",
    "    continue\n",
    "    \n",
    "    f = []\n",
    "    inter = []\n",
    "    \n",
    "    for i, elem0 in enumerate(top5_indices):\n",
    "        #print(top5_indices_res.values[i])\n",
    "        #print(elem0)\n",
    "        inter = []\n",
    "        for elem in top5_indices[max(i-2, 0):min(i+2,len(top5_indices))]:\n",
    "            l = elem.cpu().numpy().tolist()\n",
    "            if 131 in l:\n",
    "                l.remove(131)\n",
    "            if 55 in l:\n",
    "                l.remove(55)\n",
    "            if 14 in l:\n",
    "                l.remove(14)\n",
    "            if 17 in l:\n",
    "                l.remove(17)\n",
    "            inter.extend(l)\n",
    "        count_dict = Counter(inter)\n",
    "        # Get the top 5 most occurring numbers\n",
    "        top_5 = count_dict.most_common(3)\n",
    "        intermediate = []\n",
    "        for a in top_5: \n",
    "            intermediate.append(scenarios[a[0]])\n",
    "        #print(intermediate)\n",
    "        f.append(intermediate)\n",
    "    \n",
    "    #fig, axes = plt.subplots(1, 1, figsize=(12, 16))#,gridspec_kw= {'height_ratios': [20, 1]})\n",
    "    \n",
    "    plt_idx = 0\n",
    "    for i, image in tqdm(enumerate(img[0][0:])):\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(8, 16),gridspec_kw= {'height_ratios': [2, 1]})\n",
    "    \n",
    "        image_frame = (image).cpu().permute(1, 2, 0)\n",
    "\n",
    "        axes[0].imshow((np.array(image_frame) * 255).astype(np.uint8))\n",
    "        \n",
    "        title = '\\n'.join([split_string(\"\\u2022 \" + h) for h in f[i]])\n",
    "        axes[0].set_title(title)\n",
    "        axes[0].set_aspect('equal')\n",
    "        axes[0].set_xticks([])\n",
    "        axes[0].set_yticks([])\n",
    "\n",
    "        # Remove borders\n",
    "        axes[0].spines['top'].set_visible(False)\n",
    "        axes[0].spines['bottom'].set_visible(False)\n",
    "        axes[0].spines['left'].set_visible(False)\n",
    "        axes[0].spines['right'].set_visible(False)\n",
    "\n",
    "        # Plot the speed graph\n",
    "        axes[1].plot(speed_graph_2, label='Attention', color='black')\n",
    "        axes[1].plot(speed_graph_1, label='Attention', color='red')\n",
    "        axes[1].plot(speed_graph_0, label='Attention', color='green')\n",
    "    \n",
    "\n",
    "        axes[1].set_xlabel('Time Step')\n",
    "\n",
    "        axes[1].plot(i, speed_graph_2[i], marker='o', markersize=10, color='black')\n",
    "        axes[1].plot(i, speed_graph_0[i], marker='o', markersize=10, color='green')\n",
    "        axes[1].plot(i, speed_graph_1[i], marker='o', markersize=10, color='red')\n",
    "        axes[1].spines['top'].set_visible(False)\n",
    "        axes[1].spines['right'].set_visible(False)\n",
    "    \n",
    "        plt.savefig(f\"/home/jessica/personalized_driving_toyota/result_images/mturk/{i}.png\")\n",
    "        plt.close()\n",
    "\n",
    "    \n",
    "    image_directory = '/home/jessica/personalized_driving_toyota/result_images/mturk/'\n",
    "\n",
    "    # Set the output GIF file path\n",
    "    output_path = lambda x: f'/home/jessica/personalized_driving_toyota/result_images/mturk/att/w_attention_comma_{j}_{x}.mp4'\n",
    "\n",
    "    # Set the duration (in milliseconds) for each frame in the GIF\n",
    "    frame_duration = 8000\n",
    "\n",
    "    # Get a sorted list of image files in the directory\n",
    "    image_files = sorted(glob.glob(f'{image_directory}/*.png'), key=extract_number)  # Adjust the file extension if necessary\n",
    "\n",
    "    # Create a list to store the frames of the GIF\n",
    "    frames = []\n",
    "\n",
    "    # Iterate over each image file\n",
    "    for image_file in image_files:\n",
    "        # Open the image file\n",
    "        image = Image.open(image_file)\n",
    "\n",
    "        # Add the image to the list of frames\n",
    "        frames.append(image)\n",
    "\n",
    "    # Save the frames as a GIF\n",
    "    #frames[0].save(output_path(\"gif\"), format='GIF', append_images=frames[1:], save_all=True,\n",
    "    #           duration=frame_duration, loop=0)\n",
    "    imageio.mimsave(output_path(\"0\"), frames, fps=1)\n",
    "    #imageio.mimsave(output_path(\"1\"), frames[40:56], fps=2)\n",
    "\n",
    "    directory = '/home/jessica/personalized_driving_toyota/result_images/mturk'\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.png'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            os.remove(file_path)\n",
    "    if j > 50: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.11245662977183236 6.029070773500336e-17\n",
      "0.01610816052442187 0.23231406419367415\n",
      "-0.13094566029056776 1.8267099944152882e-22\n",
      "-0.19741664638210313 1.8803153058809944e-49\n",
      "-0.15893872222839175 1.9099137983836918e-32\n",
      "-0.013675870923779898 0.31056050771960253\n",
      "-0.4757347445994345 1.009059313527404e-308\n",
      "-0.012401697399036 0.35780231834691706\n",
      "-0.20074420674243412 4.16853383069545e-51\n"
     ]
    }
   ],
   "source": [
    "corr_coefficient12, p_value12 = pearsonr(sg1, angles)\n",
    "corr_coefficient13, p_value13 = pearsonr(sg2, angles)\n",
    "corr_coefficient11, p_value11 = pearsonr(sg3, angles)\n",
    "\n",
    "corr_coefficient21, p_value21 = pearsonr(sg3, dists)\n",
    "corr_coefficient22, p_value22 = pearsonr(sg1, dists)\n",
    "corr_coefficient23, p_value23 = pearsonr(sg2, dists)\n",
    "\n",
    "corr_coefficient31, p_value31 = pearsonr(sg1, vegs)\n",
    "corr_coefficient32, p_value32 = pearsonr(sg2, vegs)\n",
    "corr_coefficient33, p_value33 = pearsonr(sg3, vegs)\n",
    "\n",
    "print(corr_coefficient12, p_value12)\n",
    "print(corr_coefficient13, p_value13 )\n",
    "print(corr_coefficient11, p_value11 )\n",
    "\n",
    "print(corr_coefficient21, p_value21 )\n",
    "print(corr_coefficient22, p_value22 )\n",
    "print(corr_coefficient23, p_value23 )\n",
    "\n",
    "print(corr_coefficient31, p_value31 )\n",
    "print(corr_coefficient32, p_value32)\n",
    "print(corr_coefficient33, p_value33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5500, 5000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(angles), len(sg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for j, batch in enumerate(dataloader_nuscenes):\n",
    "#    _, image_array,  vego, angle, distance, _, _, _, _, _ = batch\n",
    "for j, batch in enumerate(dataloader_comma):\n",
    "    image_array,  vego, angle, distance, g, s, l = batch\n",
    "    img = image_array\n",
    "    max_len = 240\n",
    "    img, angle, distance, vego = img.to(gpu), angle.to(gpu), distance.to(gpu), vego.to(gpu)\n",
    "    (logits, attns), concepts = model(img, angle, distance, vego)\n",
    "    top5_indices_res = torch.tensor(concepts.squeeze()).topk(10)\n",
    "    top5_indices = top5_indices_res.indices\n",
    "    s = img.shape\n",
    "    angle, distance, vego, logits, concepts = angle.to(\"cpu\"), distance.to(\"cpu\"), vego.to(\"cpu\"), logits.detach().cpu().to(\"cpu\"), concepts.detach().cpu().to(\"cpu\")\n",
    "    \n",
    "    f = []\n",
    "    inter = []\n",
    "    img = img[:, 0:20]\n",
    "    top5_indices = top5_indices[0:20]\n",
    "    print(top5_indices.shape)\n",
    "    \n",
    "    \n",
    "    #for i, elem0 in enumerate(top5_indices):\n",
    "    #    #print(top5_indices_res.values[i])\n",
    "    #    #print(elem0)\n",
    "    #    inter = []\n",
    "    for elem in top5_indices:\n",
    "            l = elem.cpu().numpy().tolist()\n",
    "            if 131 in l:\n",
    "                l.remove(131)\n",
    "            if 55 in l:\n",
    "                l.remove(55)\n",
    "            if 14 in l:\n",
    "                l.remove(14)\n",
    "            if 17 in l:\n",
    "                l.remove(17)\n",
    "            inter.extend(l)\n",
    "            break\n",
    "    count_dict = Counter(inter)\n",
    "    # Get the top 5 most occurring numbers\n",
    "    top_5 = count_dict.most_common(3)\n",
    "    intermediate = []\n",
    "    for a in top_5: \n",
    "            intermediate.append(scenarios[a[0]])\n",
    "        #print(intermediate)\n",
    "    #    f.append(intermediate)\n",
    "    f = intermediate\n",
    "\n",
    "\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(12, 16))#,gridspec_kw= {'height_ratios': [20, 1]})\n",
    "\n",
    "    plt_idx = 0\n",
    "    for i, image in tqdm(enumerate(img[0])):\n",
    "    \n",
    "        #image_frame = (image).cpu().permute(1, 2, 0)\n",
    "        image_frame = (image).cpu().permute(1, 2, 0)\n",
    "\n",
    "        # Display the image frame\n",
    "        axes.imshow((np.array(image_frame) * 255).astype(np.uint8))\n",
    "        \n",
    "        title = '\\n'.join([split_string(\"\\u2022 \" + h) for h in f])\n",
    "        axes.set_title(title)\n",
    "        axes.set_aspect('equal')\n",
    "        axes.set_xticks([])\n",
    "        axes.set_yticks([])\n",
    "\n",
    "        # Remove borders\n",
    "        axes.spines['top'].set_visible(False)\n",
    "        axes.spines['bottom'].set_visible(False)\n",
    "        axes.spines['left'].set_visible(False)\n",
    "        axes.spines['right'].set_visible(False)\n",
    "\n",
    "        plt.savefig(f\"/home/jessica/personalized_driving_toyota/result_images/mturk/{i}.png\")\n",
    "\n",
    "    \n",
    "    image_directory = '/home/jessica/personalized_driving_toyota/result_images/mturk/'\n",
    "\n",
    "    # Set the output GIF file path\n",
    "    output_path = lambda x: f'/home/jessica/personalized_driving_toyota/result_images/mturk/att/attention_comma_{j}_{x}.mp4'\n",
    "\n",
    "    # Set the duration (in milliseconds) for each frame in the GIF\n",
    "    frame_duration = 8000\n",
    "\n",
    "    # Get a sorted list of image files in the directory\n",
    "    image_files = sorted(glob.glob(f'{image_directory}/*.png'), key=extract_number)  # Adjust the file extension if necessary\n",
    "\n",
    "    # Create a list to store the frames of the GIF\n",
    "    frames = []\n",
    "\n",
    "    # Iterate over each image file\n",
    "    for image_file in image_files:\n",
    "        # Open the image file\n",
    "        image = Image.open(image_file)\n",
    "\n",
    "        # Add the image to the list of frames\n",
    "        frames.append(image)\n",
    "\n",
    "    # Save the frames as a GIF\n",
    "    #frames[0].save(output_path(\"gif\"), format='GIF', append_images=frames[1:], save_all=True,\n",
    "    #           duration=frame_duration, loop=0)\n",
    "    imageio.mimsave(output_path(\"2\"), frames, fps=1)\n",
    "    #imageio.mimsave(output_path(\"1\"), frames[40:56], fps=2)\n",
    "    if j > 50: break\n",
    "\n",
    "    directory = '/home/jessica/personalized_driving_toyota/result_images/mturk'\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.png'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: imageio[ffmpeg] in /home/jessica/.local/lib/python3.10/site-packages (2.25.0)\n",
      "Requirement already satisfied: numpy in /home/jessica/.local/lib/python3.10/site-packages (from imageio[ffmpeg]) (1.23.5)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /usr/lib/python3/dist-packages (from imageio[ffmpeg]) (9.0.1)\n",
      "Requirement already satisfied: psutil in /home/jessica/.local/lib/python3.10/site-packages (from imageio[ffmpeg]) (5.9.4)\n",
      "Requirement already satisfied: imageio-ffmpeg in /home/jessica/.local/lib/python3.10/site-packages (from imageio[ffmpeg]) (0.4.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imageio[ffmpeg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''for j, batch in enumerate(dataloader_comma):\n",
    "    _, image_array, vego, angle, distance, m_lens, i_lens, s_lens, a_lens, d_lens = batch\n",
    "    #if (j != 4) and (j != 8) and (j != 5):\n",
    "    #    continue\n",
    "    img = image_array\n",
    "    max_len = 240\n",
    "    img, angle, distance, vego = img.to(gpu), angle.to(gpu), distance.to(gpu), vego.to(gpu)\n",
    "    (logits, attns), concepts = model(img, angle, distance, vego)\n",
    "    top5_indices = torch.tensor(concepts.squeeze()).topk(5).indices\n",
    "    s = img.shape\n",
    "    angle, distance, vego, logits, concepts = angle.to(\"cpu\"), distance.to(\"cpu\"), vego.to(\"cpu\"), logits.detach().cpu().to(\"cpu\"), concepts.detach().cpu().to(\"cpu\")\n",
    "\n",
    "    atten = attns[0][:,:,0:concepts.shape[1]].detach()\n",
    "    seq_len = atten.shape[2]\n",
    "    alignment_array = get_aligned_attention(atten.squeeze().cpu(), seq_len)\n",
    "    speed_graph_0 = alignment_array.sum(axis=0)[8:-8]\n",
    "    speed_graph_0 = moving_average(speed_graph_0, 10)\n",
    "\n",
    "    atten = attns[1][:,:,0:concepts.shape[1]].detach()\n",
    "    seq_len = atten.shape[2]\n",
    "    alignment_array = get_aligned_attention(atten.squeeze().cpu(), seq_len)\n",
    "    speed_graph_1 = alignment_array.sum(axis=0)[8:-8]\n",
    "    speed_graph_1 = moving_average(speed_graph_1, 10)\n",
    "\n",
    "    print('kkk')\n",
    "\n",
    "    atten = attns[2][:,:,0:concepts.shape[1]].detach()\n",
    "    seq_len = atten.shape[2]\n",
    "    alignment_array = get_aligned_attention(atten.squeeze().cpu(), seq_len)\n",
    "    speed_graph_2 = alignment_array.sum(axis=0)[8:-8]\n",
    "    speed_graph_2 = moving_average(speed_graph_2, 10)\n",
    "    speed_graph = speed_graph_0 + speed_graph_1 + speed_graph_2\n",
    "    #speed_graph = moving_average(speed_graph, 5)\n",
    "    \n",
    "    f = []\n",
    "    inter = []\n",
    "    for i, elem0 in enumerate(top5_indices):\n",
    "        inter = []\n",
    "        for elem in top5_indices[max(i-5, 0):min(i+5,len(top5_indices))]:\n",
    "            l = elem.cpu().numpy().tolist()\n",
    "            if 131 in l:\n",
    "                l.remove(131)\n",
    "            inter.extend(l)\n",
    "        count_dict = Counter(inter)\n",
    "        # Get the top 5 most occurring numbers\n",
    "        top_5 = count_dict.most_common(2)\n",
    "        intermediate = []\n",
    "        for a in top_5: \n",
    "            intermediate.append(scenarios[a[0]])\n",
    "        f.append(intermediate)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 8, figsize=(8, 16),gridspec_kw= {'height_ratios': [20, 1]})\n",
    "\n",
    "    plt_idx = 0\n",
    "    print('ggg')\n",
    "    for i, image in enumerate(img[0][10:-10]): \n",
    "        #arr = [0, 15, 30, 55, 90, 145, 155, 185]\n",
    "        #if i not in arr: continue\n",
    "    \n",
    "        image_frame = unorm(image).cpu().permute(1, 2, 0)\n",
    "\n",
    "        # Display the image frame\n",
    "        axes[0].imshow((np.array(image_frame) * 255).astype(np.uint8))\n",
    "        \n",
    "        title = '\\n'.join([split_string(\"\\u2022 \" + h) for h in f[i]])\n",
    "        axes[0][plt_idx].set_title(title)\n",
    "        axes[0][plt_idx].set_aspect('equal')\n",
    "        axes[0][plt_idx].set_xticks([])\n",
    "        axes[0][plt_idx].set_yticks([])\n",
    "\n",
    "        # Remove borders\n",
    "        axes[0][plt_idx].spines['top'].set_visible(False)\n",
    "        axes[0][plt_idx].spines['bottom'].set_visible(False)\n",
    "        axes[0][plt_idx].spines['left'].set_visible(False)\n",
    "        axes[0][plt_idx].spines['right'].set_visible(False)\n",
    "\n",
    "        # Plot the speed graph\n",
    "        #axes[1][plt_idx].plot(speed_graph_0[10:-10], label='Attention Head 1', color='black')\n",
    "        #axes[1][plt_idx].plot(speed_graph_1[10:-10], label='Attention Head 2', color='blue')\n",
    "        '''axes[1][plt_idx].plot(speed_graph_2[10:-10], label='Attention Head 3', color='green')\n",
    "        if i == 0:\n",
    "            axes[1][plt_idx].set_ylabel('Attention Activation')\n",
    "            axes[1][plt_idx].set_xlabel(' ')\n",
    "\n",
    "        if i == 5: \n",
    "            axes[1][plt_idx].set_xlabel('Time Step')'''\n",
    "\n",
    "        #axes[1][plt_idx].plot(i, speed_graph_0[10:-10][i], marker='o', markersize=10, color='black')\n",
    "        #axes[1][plt_idx].plot(i, speed_graph_1[10:-10][i], marker='o', markersize=10, color='blue')\n",
    "        '''axes[1][plt_idx].plot(i, speed_graph_2[10:-10][i], marker='o', markersize=30, color='green')\n",
    "        axes[1][plt_idx].spines['top'].set_visible(False)\n",
    "        axes[1][plt_idx].spines['right'].set_visible(False)'''\n",
    "\n",
    "        plt_idx +=1\n",
    "\n",
    "\n",
    "        # Adjust the plot layout if necessary\n",
    "\n",
    "        #arr = [0, 15, 20, 30, 55, 90, 145, 155, 185, 215]\n",
    "        #if i in arr: \n",
    "        plt.savefig(f\"/home/jessica/personalized_driving_toyota/result_images/mturk/{j}_{i}.pdf\")\n",
    "        #    plt.savefig(f\"/home/jessica/personalized_driving_toyota/result_images/attention_2/{j}_{i}.png\")\n",
    "        #    plt.savefig(f\"/home/jessica/personalized_driving_toyota/result_images/attention/{i}.png\")\n",
    "        #   plt_individual.append(fig)\n",
    "        #plt.clf()\n",
    "        #plt.close()\n",
    "    #fig.subplots_adjust(wspace=0.15, hspace=0.01)\n",
    "    #plt.tight_layout()\n",
    "    #plt.subplots_adjust(top=0.85)\n",
    "    #plt.savefig(f\"/home/jessica/personalized_driving_toyota/result_images/mturk/attention_3/{j}.pdf\")\n",
    "    #plt.show()\n",
    "    \n",
    "    image_directory = '/home/jessica/personalized_driving_toyota/result_images/mturk/'\n",
    "\n",
    "    # Set the output GIF file path\n",
    "    output_path = lambda x: f'/home/jessica/personalized_driving_toyota/result_images/mturk/attention_comma_{j}.{x}'\n",
    "\n",
    "    # Set the duration (in milliseconds) for each frame in the GIF\n",
    "    frame_duration = 500\n",
    "\n",
    "    # Get a sorted list of image files in the directory\n",
    "    image_files = sorted(glob.glob(f'{image_directory}/*.png'), key=extract_number)  # Adjust the file extension if necessary\n",
    "\n",
    "    # Create a list to store the frames of the GIF\n",
    "    frames = []\n",
    "\n",
    "    # Iterate over each image file\n",
    "    for image_file in image_files:\n",
    "        # Open the image file\n",
    "        image = Image.open(image_file)\n",
    "\n",
    "        # Add the image to the list of frames\n",
    "        frames.append(image)\n",
    "\n",
    "    # Save the frames as a GIF\n",
    "    frames[0].save(output_path(\"gif\"), format='GIF', append_images=frames[1:], save_all=True,\n",
    "                duration=frame_duration, loop=0)\n",
    "    imageio.mimsave(output_path(\"mp4\"), frames, fps=30)  # Adjust the fps as needed\n",
    "    normalized_weights = atten#np.array(attention_weights) / np.sum(attention_weights)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    heatmap = ax.pcolormesh(alignment_array[0:70, :], cmap='hot')\n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(heatmap)\n",
    "\n",
    "    # Add labels and title\n",
    "    ax.set_xlabel('Sequence Position')\n",
    "    ax.set_ylabel('Window')\n",
    "    ax.set_title('Longformer Sliding Chunk Attention')\n",
    "\n",
    "    # Show the plot\n",
    "    #plt.savefig(f\"/home/jessica/personalized_driving_toyota/attention_vis{j}.pdf\")\n",
    "    plt.close()\n",
    "    break'''\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
